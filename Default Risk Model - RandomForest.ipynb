{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "\n",
    "import sys\n",
    "print (sys.version)\n",
    "\n",
    "# need to work with excel formatted dates and re:\n",
    "import datetime\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=r'C:\\Users\\joogl\\Assessments\\Fair Assessment\\Fair Data\\train_data.csv'\n",
    "df = pd.read_csv(data, nrows=200000, parse_dates=['earliest_cr_line', 'apply_date'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Characteristics (Text)\n",
    "print('LOAN PURPOSE:')\n",
    "print(df['purpose'].unique())\n",
    "print(\"--------------------------\")\n",
    "print('LOAN STATUS:')\n",
    "print(df['loan_status'].unique())\n",
    "print(\"--------------------------\")\n",
    "print('LOAN TITLE:')\n",
    "print(df['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrower Characteristics (Text)\n",
    "print('BORROWER STATE:')\n",
    "print(df['addr_state'].unique())\n",
    "print(df.groupby(['addr_state']).size())\n",
    "print(\"--------------------------\")\n",
    "print('BORROWER JOB TITLE:')\n",
    "print(df['emp_title'].unique())\n",
    "print(\"--------------------------\")\n",
    "print('BORROWER HOME TYPE:')\n",
    "print(df['home_ownership'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "I. Explore Continuous Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Continuous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dti = df['dti']\n",
    "print('dti --> (avg monthly debt payments/annual income): min: {}, max: {}, mean: {}, sd: {}'.format(\n",
    "    round(df_dti.min(), 2),\n",
    "    round(df_dti.max(), 2),\n",
    "    round(df_dti.mean(), 2),\n",
    "    round(df_dti.std(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_up = {'01': 'Jan', '02': 'Feb', '03': 'Mar', '04': 'Apr', '05': 'May',\n",
    "            '06': 'Jun', '07': 'Jul', '08': 'Aug', '09': 'Sep', '10': 'Oct', '11': 'Nov', '12': 'Dec'}\n",
    "inv_map = {v: k for k, v in look_up.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean earliest_cr_line\n",
    "\n",
    "new_credit_date = pd.DataFrame([], columns=['credit_date'])\n",
    "print(new_credit_date)\n",
    "\n",
    "fd_date = pd.to_datetime(df['earliest_cr_line'], errors='coerce')\n",
    "fd_date = fd_date.map(lambda x: x - pd.DateOffset(years=100) if x.year>2018 else x)\n",
    "\n",
    "for n, element in enumerate(fd_date):\n",
    "    #print(\"---------------\")\n",
    "    #print(n)\n",
    "        \n",
    "    if str(element) == 'NaT':\n",
    "        if (str(df['earliest_cr_line'][n]))=='nan':\n",
    "            fd_date = np.nan\n",
    "        elif str(df['earliest_cr_line'][n]).split(\"-\")[1] == '00':\n",
    "            fd_date = datetime.datetime(2000, int(inv_map[df['earliest_cr_line'][n].split(\"-\")[0]]), 1).date()\n",
    "        else:\n",
    "            fd_date = datetime.datetime(2017, datetime.datetime.strptime(df['earliest_cr_line'][n], '%d-%b').month, \\\n",
    "                                    datetime.datetime.strptime(df['earliest_cr_line'][n], '%d-%b').day).date()\n",
    "        #print(fd_date)\n",
    "        new_credit_date = new_credit_date.append({'credit_date': fd_date}, ignore_index=True)\n",
    "    else:\n",
    "        #print(element)\n",
    "        new_credit_date = new_credit_date.append({'credit_date': element.date()}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean apply_date. All years are 2017.\n",
    "\n",
    "apply_dates = pd.to_datetime(df.apply_date, format='%d-%b').apply(lambda x: x + pd.DateOffset(years=117))\n",
    "print(apply_dates[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean emp_length (need to get integer)\n",
    "emp_length_int = df['emp_length'].str.replace(r'\\D+', '')\n",
    "print(emp_length_int[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ignore emp_title (probably highly correlated with income even when cleaned)\n",
    "# Ignore mths_since_last_major_derog (too sparse)\n",
    "# Ignore Loan Title (too many categories and probably highly correlated with loan purpose)\n",
    "# Ignore verification_status_joint (too sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform new_credit_date to days since earliest credit line (use timedelta)\n",
    "\n",
    "df_crl = new_credit_date['credit_date']\n",
    "\n",
    "present_date = pd.DataFrame(index=range(len(df_crl)), columns=['tdate'])\n",
    "present_date['tdate'] = pd.Timestamp('2018-03-01')\n",
    "t_date = pd.to_datetime(present_date.tdate, format='%Y-%m-%d')\n",
    "c_date = pd.to_datetime(df_crl, format='%Y-%m-%d')\n",
    "\n",
    "#print(t_date[0:5])\n",
    "#print(c_date[0:5])\n",
    "\n",
    "credit_days = t_date - c_date \n",
    "#print(credit_days)\n",
    "\n",
    "credit_days_df = pd.DataFrame(credit_days, columns=['days'])\n",
    "#print(credit_days_df[0:5])\n",
    "credit_days_df = credit_days_df['days'].astype(datetime.timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "print(credit_days_df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform new_credit_date to days since earliest credit line (use timedelta)\n",
    "\n",
    "apply_days = t_date - apply_dates\n",
    "#print(apply_days)\n",
    "\n",
    "apply_days_df = pd.DataFrame(apply_days, columns=['days'])\n",
    "#print(apply_days_df[0:5])\n",
    "apply_days_df = apply_days_df['days'].astype(datetime.timedelta).map(lambda x: np.nan if pd.isnull(x) else x.days)\n",
    "print(apply_days_df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('credit days --> (number of days since first credit line opened): min: {}, max: {}, mean: {}, sd: {}'.format(\n",
    "    round(credit_days_df.min(), 2),\n",
    "    round(credit_days_df.max(), 2),\n",
    "    round(credit_days_df.mean(), 2),\n",
    "    round(credit_days_df.std(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('application days --> (number of days since application opened): min: {}, max: {}, mean: {}, sd: {}'.format(\n",
    "    round(apply_days_df.min(), 2),\n",
    "    round(apply_days_df.max(), 2),\n",
    "    round(apply_days_df.mean(), 2),\n",
    "    round(apply_days_df.std(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_credit = df['revol_bal']\n",
    "print('revol_bal --> (Remaining Credit Line): min: {}, max: {}, mean: {}, sd: {}'.format(\n",
    "    round(rm_credit.min(), 2),\n",
    "    round(rm_credit.max(), 2),\n",
    "    round(rm_credit.mean(), 2),\n",
    "    round(rm_credit.std(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_income = df['annual_inc']\n",
    "print('annual_inc --> (Annual Income): min: {}, max: {}, mean: {}, sd: {}'.format(\n",
    "    round(ann_income.min(), 2),\n",
    "    round(ann_income.max(), 2),\n",
    "    round(ann_income.mean(), 2),\n",
    "    round(ann_income.std(), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One-Hot Encoding on String Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hot_encoding(pd_column):\n",
    "    # Purpose: applies 1 hot encoding to categrical variables\n",
    "    # Output: pd dataframe. Columns use dataframe input column name as prefix\n",
    "    prefix = pd_column.name\n",
    "    \n",
    "    dummy = OneHotEncoder()\n",
    "    dummyC = LabelEncoder()\n",
    "    df_cat2 = np.zeros((pd_column.shape[0], 1))\n",
    "    y = dummyC.fit_transform(pd_column.reshape(-1, 1))\n",
    "    y = dummy.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "    y = pd.DataFrame(y[:, 1:])\n",
    "    df_cat2 = np.hstack((df_cat2, y))\n",
    "    \n",
    "    df_stuff = pd.DataFrame(df_cat2)\n",
    "    df_stuff.columns = [str(prefix)+str(\"_\")+str(n) for n in list(df_stuff.columns)]\n",
    "    \n",
    "    return pd.DataFrame(df_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt - Geography\n",
    "\n",
    "geog = hot_encoding(df['addr_state'])\n",
    "print(geog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt - Home Type\n",
    "home_type = hot_encoding(df['home_ownership'])\n",
    "print(home_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt - Loan Status\n",
    "# loan_status = hot_encoding(df['loan_status'])\n",
    "# avoid using function since we want to specifically drop the default category and use the rest of the data as covariates\n",
    "\n",
    "prefix = df['loan_status'].name\n",
    "\n",
    "dummy = OneHotEncoder()\n",
    "dummyC = LabelEncoder()\n",
    "df_cat2 = np.zeros((df['loan_status'].shape[0], 1))\n",
    "y = dummyC.fit_transform(df['loan_status'].reshape(-1, 1))\n",
    "y = dummy.fit_transform(y.reshape(-1, 1)).toarray()\n",
    "\n",
    "df_cat2 = np.hstack((df_cat2, y))\n",
    "\n",
    "df_stuff = pd.DataFrame(df_cat2)\n",
    "df_stuff.columns = [str(prefix)+str(\"_\")+str(n) for n in list(df_stuff.columns)]\n",
    "# drop default variable\n",
    "# test: df['loan_status'].unique()\n",
    "# test: df['loan_status'][702]\n",
    "# test: loan_status['loan_status_3'][2296]\n",
    " \n",
    "loan_status = pd.DataFrame(df_stuff)\n",
    "loan_status.drop(['loan_status_3'], axis=1, inplace=True)    # loan status = default\n",
    "loan_status.drop(['loan_status_1'], axis=1, inplace=True)    # loan status = charged-off\n",
    "loan_status.drop(['loan_status_10'], axis=1, inplace=True)   # loan status = 30+ days late\n",
    "print(loan_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Txt - loan Purpose\n",
    "loan_purpose = hot_encoding(df['purpose'])\n",
    "print(loan_purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bool - Verfied Income\n",
    "verified_income = hot_encoding(df['verification_status'])\n",
    "print(verified_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a merged dataframe from the following vectors:\n",
    "\n",
    "# verified_income\n",
    "# loan_purpose\n",
    "# loan_status\n",
    "# home_type\n",
    "# geog\n",
    "#\n",
    "# ann_income\n",
    "# rm_credit\n",
    "# apply_days_df\n",
    "# credit_days_df\n",
    "# df_dti\n",
    "# emp_length_int\n",
    "\n",
    "\"\"\"\n",
    "plt.hist(df_dti)\n",
    "plt.hist(emp_length_int)\n",
    "plt.hist(credit_days_df.dropna(axis=0, how='any'))\n",
    "plt.hist(rm_credit)\n",
    "plt.hist(ann_income.dropna(axis=0, how='any'))\n",
    "\n",
    "print(len(ann_income)) #\n",
    "print(len(rm_credit)) #\n",
    "print(len(apply_days_df)) #\n",
    "print(len(credit_days_df)) #\n",
    "print(len(df_dti)) #\n",
    "print(len(emp_length_int)) #\n",
    "print(len(verified_income))\n",
    "print(len(loan_purpose))\n",
    "print(len(loan_status))\n",
    "print(len(home_type))\n",
    "print(len(geog))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ann_income_pd = ann_income.to_frame('ann_income')\n",
    "rm_credit_pd = rm_credit.to_frame('rm_credit')\n",
    "apply_days_pd = apply_days_df.to_frame('apply_days')\n",
    "credit_days_pd = credit_days_df.to_frame('credit_days')\n",
    "dti_pd = df_dti.to_frame('dti')\n",
    "emp_length_pd = emp_length_int.to_frame('emp_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_default = df.loan_status.apply(lambda x: 1 if x in {'Default', 'Late (31-120 days)', 'Charged Off'} else 0)\n",
    "df_default = df_default.to_frame('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfs = [df_default, ann_income_pd, rm_credit_pd, apply_days_pd, credit_days_pd, dti_pd, emp_length_pd, \\\n",
    "      verified_income, loan_purpose, loan_status, home_type, geog]\n",
    "dfs = [df.reset_index() for df in dfs]\n",
    "\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='index'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any rows with NA before analysis (if regressions fail)\n",
    "#print(len(df_final))\n",
    "df_final = df_final.dropna(axis=0, how='any')\n",
    "#print(len(df_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Modeling the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_final[[x for x in df_final.columns if x != 'default' and x != 'index']]\n",
    "y = df_final[['default']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(len(X_test))\n",
    "X_test = X_test.dropna(axis=0, how='any')\n",
    "#print(len(X_test))\n",
    "#print(len(y_test))\n",
    "#print(y_test)\n",
    "\n",
    "#print(len(X_train))\n",
    "X_train = X_train.dropna(axis=0, how='any')\n",
    "#print(len(X_train))\n",
    "#print(len(y_train))\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale features to have same variance\n",
    "sc = StandardScaler()\n",
    "X_train_cont = sc.fit_transform(X_train)\n",
    "X_test_cont = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(model, X, y):\n",
    "    if model == 'lr':\n",
    "        myModel = LogisticRegression(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    elif model == 'svm':\n",
    "        myModel = SVC(kernel='linear', random_state=42, class_weight='balanced', cache_size=2048)\n",
    "    elif model == 'rf':\n",
    "        myModel = RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "    else:\n",
    "        raise error('cannot fit that model')\n",
    "    \n",
    "    myModel.fit(X, y)\n",
    "    \n",
    "    if model == 'lr':\n",
    "        y_pred_probs = myModel.predict_proba(X)\n",
    "        y_pred = myModel.predict(X)\n",
    "    else:\n",
    "        y_pred = myModel.predict(X)\n",
    "        in_acc = accuracy_score(y_pred, y)\n",
    "    print(y_pred)\n",
    "    print(y)\n",
    "    in_RMSE = np.sqrt(mean_squared_error(y_pred, y))\n",
    "    in_acc = accuracy_score(y_pred, y)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred, y).ravel()\n",
    "    print('Accuracy: {}, Precision: {}, Recall: {}'.format(round(in_acc, 2), tp / (tp + fp), tp / (tp + fn)))\n",
    "    print(pd.DataFrame(confusion_matrix(y_pred, y)))\n",
    "    \n",
    "    return y_pred, myModel, in_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1, model1, in_RMSE1 = create_model('lr', X_train, y_train[:,0])\n",
    "# pred2 = create_model('svm', X_train, y_train[:,0])\n",
    "pred3, model3, in_RMSE3 = create_model('rf', X_train, y_train[:,0])\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_pred = pd.Series(pred1 * 0.67)\n",
    "# svm_pred = pd.Series(pred2 * 0.79)\n",
    "rf_pred = pd.Series(pred3 * 0.96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Precision (using confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.DataFrame([lr_pred, rf_pred]).sum()\n",
    "final_pred = final_pred.apply(lambda x: 1 if x > 1 else 0)\n",
    "in_acc = accuracy_score(final_pred, y_train[:,0])\n",
    "tn, fp, fn, tp = confusion_matrix(final_pred, y_train[:,0]).ravel()\n",
    "print('Accuracy: {}, Precision: {}, Recall: {}'.format(round(in_acc, 2), tp / (tp + fp), tp / (tp + fn)))\n",
    "confusion_matrix(final_pred, y_train[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Modeling the Test Set (using Logistic Regression Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "\n",
    "out_acc = accuracy_score(y_pred, y_test[:,0])\n",
    "out_RMSE = np.sqrt(mean_squared_error(y_pred, y_test[:,0]))\n",
    "                   \n",
    "tn, fp, fn, tp = confusion_matrix(y_pred, y_test[:,0]).ravel()\n",
    "print('In-sample accuracy: {}, Precision: {}, Recall: {}'.format(round(out_acc, 2), tp / (tp + fp), tp / (tp + fn)))\n",
    "confusion_matrix(y_pred, y_test[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get in and out of sample accuracy\n",
    "# pred1\n",
    "# in_RMSE3\n",
    "\n",
    "rSquared = model3.score(X_test, y_test[:,0])\n",
    "print('In-sample RMSE: {}\\nOut-of-sample RMSE: {}\\nRsquared: {}'.format(in_RMSE3, out_RMSE, rSquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(model1.coef_))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefficients)\n",
    "print(\"End.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
